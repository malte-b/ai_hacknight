# ai_hacknight

## Assembly AI Challenge

Number of sentences: 363

### "How many times did they mention the word 'weaviate'?"
The word 'weaviate' is mentioned 9 times in the transcript.

--> actually I checked it's 11 times, so the LLM is wrong here, because we would need an agent for aggergation

### "Outline the main points of the podcast."
Here's an outline of the main points discussed in the podcast:

1. Introduction to Agentic RAG
   - Components of an agent: language model, memory, planning, tools
   - Difference between vanilla RAG and Agentic RAG

2. Planning in Agent Systems
   - Discussion of different planning approaches (React, Chain of Thought, Tree of Thoughts)
   - Comparison of planning methods and their potential applications

3. Multi-Agent Systems
   - Structure of multi-agent systems (top-level agent, specialized sub-agents)
   - Benefits of using different language models for different roles
   - Comparison to DSPY framework

4. Memory in Agent Systems
   - Short-term vs. long-term memory
   - Discussion of Letta framework for updating agent memory

5. Evaluation and Observability in AI Systems
   - Tools for observability (Arises, Telemetry, Phoenix)
   - Challenges with using LLMs as judges
   - Ensembling and sampling multiple inferences for more robust results

6. Developer Experience for Building Agents
   - Challenges in defining tools and functions
   - Potential for low-code/no-code solutions

7. Generative Feedback Loops (GFLs)
   - Role of agents in GFLs
   - Long-running processes for content generation
   - Integration with external tools and data sources

8. Human-in-the-Loop Considerations
   - Importance of human oversight in autonomous systems
   - Balancing AI autonomy with human control

9. Future Directions
   - Potential for storing and reusing intermediate outputs in complex tasks
   - AI-native businesses leveraging generative feedback loops

The podcast concludes with a mention of an upcoming event in New York City where these topics will be further discussed.